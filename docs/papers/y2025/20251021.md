import blog_20251021_img0 from './asset/blog_20251021_img0.png';
import blog_20251021_img1 from './asset/blog_20251021_img1.png';
import blog_20251021_img2 from './asset/blog_20251021_img2.png';
import blog_20251021_img2 from './asset/blog_20251021_img3.png';

# 10-21 papers summary

## 1. [DISTRACTOR INJECTION ATTACKS ON LARGE REASONING MODELS](https://arxiv.org/pdf/2510.16259) `amazon`
### CHARACTERIZATION AND DEFENSE

LRM 모델에서 프롬프트 주입이 아니라 추론 과정 자체를 악의적으로 공격하는 방식에 SOTA 모델들이 매우 취약하다고 주장하고, 방어전략을 제안함.

## 2. [Enterprise Deep Research](https://arxiv.org/pdf/2510.17797) `salesforce`
### Steerable MultiAgent Deep Research for Enterprise Analytics

industry level 은 비정형 데이터를 정형화되고, 기업에서 사용할 수 있는 형태의 정보로 변환해야하지만 기존의 자율 에이전트 도메인 특유의 뉘앙스, 의도 정렬, 기업 통합에서 어려움을 겪는다. 기존 심층 연구 시스템은 사용자가 중간 추론 과정에 개입할 수 없어 연구 방향을 steering 할 수 없었고, 이로 인해 비효율적이거나 사용자 의도에 맞지 않는 결과가 생성되었다.

기업은 특히 투명한 증거 근거(Evidence) 가 필요하다.

EDR 은 투명하고 조종가능한 multi-agent-system 을 제안함. Enterprise Deep research Framework.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251021_img0} style={{width: 500}} />
</div>

유저 쿼리로부터 연구에 필요한 과정에 전문화된 에이전트를 도입한다. 사용자는 이 과정에서 자연어로 연구 지침을 master research agent 에 전달 가능하다. 

세일즈 포스는 일반적인 문제 해결에서 한 단계 더 나가고 있는듯.

## 3. [UltraCUA](https://arxiv.org/pdf/2510.17790) `apple`
### A Foundation Model for Computer Use Agents with Hybrid Action

Computer-use Agent 방식은 컴퓨터의 기본적 동작에 의존했다. 다른 에이전트들은 API 또는 MCP 를 적극적으로 활용한다.

UltraCUA 는 Computer-use Agent 에 API 와 MCP 같은 고수준 프로그래밍 도구를 적극적으로 활용하는 방식을 제안함.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251021_img1} style={{width: 500}} />
</div>

## 4. [Embody 3D](https://arxiv.org/pdf/2510.16258) `meta`
### A Large-scale Multimodal Motion and Behavior Dataset

고품질, 대규모 3D 모션 데이터셑. 439명 참가자로부터 총 500 시간 분량 데이터를 수집하여 역대 최대 규모 3D 모션 데이터셑 구축함.

손, 얼굴 표정, 신체 형태를 포함하여 전신을 추적하는 3D 모션 데이터.
참가자별로 분리된 오디오 트랙과 상세한 텍스트 주석이 포함된 오디오 데이터.

다양한 일상 활동, 협업 ,감정적 대화 등 복잡한 행동 데이터 포함됨. 범용적인 인간 행동을 최대한 많이 포함.

## 5. [DLER: Doing Length pEnalty Right](https://arxiv.org/pdf/2510.15110) `nvidia`
### Incentivizing More Intelligence per Token via Reinforcement Learning

LLM 에서 긴 CoT 를 사용하면 높은 정확도를 달성할 수 있지만, 불필요하게 긴 출력을 생성해서 토큰이 낭비되고 레이턴시도 높아진다. 

기존 GRPO 효율성 개선 논문은 정확도 보상과 길이 페널티를 함께 사용함. 이 방식은 그런데 정확도를 손해봐왔음. 이는 길이 페널티의 문제가 아니라, 최적화를 적절하게 하지 못해왔기 떄문이라고 주장하고, DLER 제안.

DLER 은 3가지 전략.
1) batch-wise reward normalization -> 분산 안정화
2) higher clipping -> entropy collapse 방지
3) dynamic sampling -> sparse reward signal 해결.

:::tip

entropy collapse : RL 훈련 과정에서 모델의 정책이 너무 빠르게 deterministic 해져서 엔트로피가 급격히 낮아져서 새로운 탐색이 제한되는 현상. GRPO 알고리즘의 policy clipping 이 문제의 원인이라고 지적. 예를 들어서, "Wait, let me rethink" 와 같은 고엔트로피 토큰들을 clipping 이 막아버림. DLER 은 간단하게 clipping threshold 를 더 높음.

:::

:::tip

sparse reward signal : 모델이 학습할 수 있는 보상 정보가 부족하거나, 훈련 배치내에서 보상 정보의 분포가 극도로 불균형한 상태. 길이 페널티는 출력이 제한 길이를 초과하면 보상을 0으로 보내버림.
그런데 훈련 초기에는 모델이 아직 길이를 제어하지 못해 대부분의 응답이 제한 길이를 초과하고 보상이 0이 됨. 이로 인해 신호가 적어 훈련이 느려지게 됨.
훈련 후기에는, 모델이 짧게만 응답해서 쉬운 프롬프트는 학습이 되고, 어려운 프롬프트는 보상을 받지 못함. 모델이 쉬운 문제에 과적합해서 어려운 문제는 길게 생각하는 걸 할줄모르게 됨. dynamic batch 는 모든 rollout 에서 0 또는 1 보상을 받은 프롬프트, 즉 너무 쉽거나 너무 어려운 프롬프트를 동적으로 필터링해서 다음 훈련 배치에서 제외함. 학습하기 좋은 프롬프트를 많이 학습시키는 것.
:::

## 6. [Train a Unified Multimodal Data Quality Classifier with Synthetic Data](https://arxiv.org/pdf/2510.15162)

Interleaved Document Data 의 품질 필터링 방법이 마땅치 않다. 이미지-텍스트 데이터의 경우 대표적인게 CLIPScore 인데 CLIPScore 는 단일 이미지-텍스트 쌍만 처리 가능하다.

UniFilter 는 MLLM 을 Multimodal data quality filter 로 훈련해서 사용하는 방식에 대한 논문. Interleaved Document 와 Image-Text Caption 모두의 품질을 분류함. Intereaved Document 의 경우 문서에서 이미지와 텍스트를 추출해서 사용함.

- 데이터 : 원본 이미지에 대해 proprietrary mllm 사용해서 4단계 품질 레벨에 따른 요구사항을 포함한 텍스트를 생성.
- 훈련 : 데이터 사용해서 훈련함. MSE Loss 와, MSE Loss with Label 을 사용. MSE loss with label 은 4단계 품질 레벨을 맞춰야함.

## 7. [Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation](https://arxiv.org/pdf/2510.17354)

기존 RA 시스템은 주로 Unimodal Text Document 에 초점이 맞추어져 있어서 multimodal document 검색 성능이 취약했다. multimodal rag 방법론은 image-text 의 관계를 파악하는 능력이 떨어졌고.

Unified Mixed-Modal-to-Mixed-modal retriever 방법론 제안.

역시 LLM 을 통해 데이터 구축하고 학습한 논문.

## 8. [FineVision: Open Data Is All You Need](https://arxiv.org/pdf/2510.17269) `huggingface`

<div style={{textAlign: 'center'}}>
 <img src={blog_20251021_img2} style={{width: 500}} />
</div>

https://huggingface.co/spaces/HuggingFaceM4/FineVision 

HuggingFace 에서 제작하고 공개하는 대규모 VLM corpus.

2500만개 이상 샘플, 1700만개 이상의 이미지로 되어 있고, 데이터 품질을 열심히 높였다고 합니다. 해당 데이터로 학습한 VLM 모델들은 거의 일관적으로 모델 성능이 크게 향상되었다고 함.


## 9. [DEEP SELF-EVOLVING REASONING](https://arxiv.org/pdf/2510.17498) `microsoft`

CoT 과정에서 더 작은 모델로 더 나은 효율성을 달성하는 것에 중점을 둔다. 

CoT 방식은 발전했지만, 기존의 Verification-Refinement framework 발전이 약간 멈췄다. 특히 오픈 소스 모델들은 self-verification 능력이 약했음. (자기 답을 자기가 평가하니)

논문에서는 검증 및 개선 결과가 확률적으로 이루어지므로, 수많은 시행을 거치면 더 정확하게 추론할 수 있다고 이야기 한다.  

1. DSER Process
  - N 번의 verification-refinement 과정을 거쳐 답변의 변화를 확인한다.
  - self-verification 능력이 약하므로 대부분의 경우 답변은 그대로다. 
  - 다만, 답변이 변하는 경우만 고려해서 확인해보면 "개선" 되는 경우가 "악화" 되는 경우보다 많음을 논문에서 확인한다.
  - 논문에서는 markov chain 을 이용해 수학적으로 모델링하지만, 결론은 verification-refinement 를 충분히 많이하면 "개선" 된 답변일 확률이 매우 높아진다.
2. majority vote
  - DSER Process 를 K 개 병렬 실행한 뒤, 최종 답변은 mojority vote 를 이용해서 정한다.

deepseek 모델 사용. 8B 모델로 600B teahcer-model 성능을 능가했다고 함. **모델의 크기-latency trade-off 를 효과적으로 달성**함. 또한 AIME 2024-2025 벤치마크 미해결 문제 9개 중 5개를 해결. (기존 verification-dependent 방법은 2개만 해결함.)

## 10. [VISTA](https://arxiv.org/pdf/2510.15831) `google`
### A Test-Time Self-Improving Video Generation Agent

## 11. [Emergent Misalignment via In-Context Learning](https://arxiv.org/pdf/2510.11288) 
### Narrow in-context examples can produce broadly misaligned LLMs

Emergent Misalignment 현상은 LLM 이 좁은 도메인의 Misaligned Training Data 에 노출된 후, Broadly Harmful Behavior 을 보이는 현상.

예를 들어서, 경제 관련 유해한 텍스트를 학습한 모델이 건강 관련 질의에 갑자기 유해한 대답을 하는 현상임.

이 현상이 SFT 나 Activation Steering(Persona Vector) 사용시 발생하는 것은 확인되었으나, ICL 에서도 밠생하는지 확인 안됐음.

확인해본 결과 발생함. 64개 ICL 시 2% ~ 17% 발생. 256개 사용시 최대 58% 까지 발생함.

## 12. [NANO3D](https://arxiv.org/pdf/2510.15019) `tsinghua`
### A TRAINING-FREE APPROACH FOR EFFICIENT 3D EDITING WITHOUT MASKS

3D 객체 편집 기존 접근법은 비효율적이었고, fine-grained details 나 편집 되지 않은 영역 보존에 실패함. 기존 방법은 대부분 **다중 뷰 렌더링 편집 후 재구성** 하는 방식. 3d 편집은 training-free 알고리즘과 대규모 데이터셑 부재로 인해 초기 단계에 머물러 있음.

mask 가 필요없는 3d 객체 편집 모델 제안.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251021_img3} style={{width: 500}} />
</div>

2d 이미지 편집 기술을 3D 객체 voxel 편집에 도입함. 그리고 편집된 영역만 정확히 식별해서 나머지 영역은 원본을 유지하도록 함.

## 13. [OmniVinci](https://arxiv.org/pdf/2510.15870) `nvidia`
### Enhancing Architecture and Data for Omni-Modal Understanding LLM

Video-Audio Alignment 를 포함하는 Omni-modal 시스템 훈련은 비용이 매우 큼. 

OmniVinchi 는 opensource omni-modal llm 구축 프로젝트를 소개함.

- 모델 아키텍쳐 제안 : OmniVinchi
- 데이터 : 24M Omni-modal conversation curation

## 14. [Language Models Model Language](https://arxiv.org/pdf/2510.12766)

언어학자가 쓴 논문. LLM 이 진짜 "언어" 를 모델링하고 있는게 아니라는 학계의 반응을 비판하며 LLM 이 실제로 언어를 모델링 하고 있음을 인정해야 한다는 내용.

언어학자들이 이야기하는 추상적인 이론적 요구사항 - 기호, 정신적 능력 - 을 충족시킬 필요가 없다고 이야기합니다. 

- Manczak 의 주장
언어는 말해지고 쓰여지는 것의 총체이며, 빈도가 그 조직원리다. 문법이란 고빈도 패턴이며, 예외는 저빈도 패턴일 뿐 질적인 차이가 없다. 언어학에서 보여지는 모든 현상을 이 관점에서 설명할 수 있다.

LLM 은 이 Manczak 의 통찰이 옳다는 것을 증명하고 있으며, 말해지고 쓰여지는 모든 것들의 확률을 기반으로 언어를 훌륭하게 모델링하고 있다. 

더 나아가서 LLM 의 언어 능력은 언어의 추상적 요구 사항을 충족시키기 위해 노력해서는 발전할 수 없으며, 언어의 관계적 논리 능력을 발전시키기 위해 노력해야 발전할 수 있다고 주장합니다. - 추상적 요구 사항 자체가 언어의 특성에 대한 잘못된 해석이다!

## 15. [RL makes MLLMs see better than SFT](https://arxiv.org/pdf/2510.16333) `naver`

MLLM 의 시각 이해 능력은 SFT 보다 RL 에 의해 더욱 정확해진다.
