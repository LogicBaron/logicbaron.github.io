import blog_20251027_img0 from './asset/blog_20251027_img0.png';
import blog_20251027_img1 from './asset/blog_20251027_img1.png';

# 2025-10-26 papers review

##  1. [Video-As-Prompt](https://huggingface.co/papers/2510.20888) `bytedance`  
### Unified Semantic Control for Video Generation

비디오 자체를 비디오 생성의 prompt, reference 로 사용하는 방법 제안. 일종의 video in-context generation.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251027_img0} style={{width: 500}} />
</div>

생성 방식은 비디오 생성 DiT 와 별개로, prompt video 를 처리하는 transformer: expert - 를 별도로 사용한다.

expert 와 DiT 는 서로 일부 attention 을 완전히 공유하며, 최종적으로 main DiT 의 생성 결과를 사용하게 된다.

이 구조는 비디오의 스타일을 적용한 결과물을 생성하도록 학습하는데, 이 과정에서 expert 만 trainable 로 설정.

## 2. [Search Self-play](https://huggingface.co/papers/2510.18821)
### Pushing the Frontier of Agent Capability without Supervision

Agent 훈련을 위한 RLVR (Reinforcement Learning with Verifiable Rewards) 을 검증된 정답셋 없이 LLM 의 self-play 를 통해 달성하려함. 정확히는 **정답은 있지만 질의는 없는 경우** 를 위한 것.

LLM proposer(질의자), solver(풀이자) 를 놔둠.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251027_img1} style={{width: 500}} />
</div>

- LLM proposer: 정답에 맞는 질의를 multi-turn search tool call 을 통해서 생성 -> generated question
- LLM solver : 두 가지 역할을 수행함.
  - 1. 먼저 LLM proposer 가 사용한 RAG 결과를 사용하면 generated question -> ground-truth answer 추론이 가능한지 확인.
  - 2. 1 통과되면, 자기가 신규로 search tool 을 사용해서 generated question 으로부터 정답 추론. 이 정답을 이용해서 모델 학습시켜 나감.

LLM proposer 는 점점 어렵게 질문을 만드려 하고, LLM solver 는 더 정답을 잘 맞추려고 함. zero-sum game 을 하면서 모델이 발전해나감. 

논문은 오픈 데이터셑에서 쿼리를 제거한 데이터로 실험함. 큰 모델에서는 실험을 못해본 것 같은데 작은 모델 기준으로는 성능 향상을 확인함.

## 3. [Foley Control](https://huggingface.co/papers/2510.21581) `stability ai`
### Aligning a Frozen Latent Text-to-Audio Model to Video

end-to-end 시스템을 거부한다. Video-to-Audio 모델은 end-to-end 로 학습하려면 대규모의 데이터셑, 막대한 계산 비용이 필요함.

Audio DiT 모델과 Video Encoder 를 Frozen 상태로 두고 가벼운 video cross-attention 브릿지만을 학습시킴.

동기화 성능 저하는 없었다. stability AI 다운 노하우가 많이 들어있을 것 같음.

## 4. [Soft Instruction De-escalation Defense](https://huggingface.co/papers/2510.21057)

prompt injection 방식 공격에 대한 [논문](/docs/papers/y2025/oct/20251021#1-distractor-injection-attacks-on-large-reasoning-models-amazon)을 몇개 소개했는데, 같은 계열이다.