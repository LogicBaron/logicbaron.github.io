import blog_20251022_img0 from './asset/blog_20251022_img0.png';
import blog_20251022_img1 from './asset/blog_20251022_img1.png';

# 10-22 papers summary

## 1. [MoGA](https://huggingface.co/papers/2510.18692) `bytedance`
### Mixture-of-Groups Attention for End-to-End Long Video Generation

## 2. [Grasp Any Region](https://arxiv.org/pdf/2510.18876) `bytedance`
### Towards Precise, Contextual Pixel Understanding for Multimodal LLMs

MLLM 논문의 전체 이미지 이해 능력 -> 복잡한 장면의 dense understanding + 미세한 pixel understanding 을 달성할 수 있도록 돞는 새로운 프레임 워크인 Grasp Any Region 을 제안.

전체 이미지 feature map 일단 확보해두고, Region base featrure 도 추출하는 방식.

## 3. [ProCLIP](https://arxiv.org/pdf/2510.18795)
### Progressive Vision-Language Alignment via LLM-based Embedder

CLIP text encdoer 를 BERT -> LLM-based embedder 로 대체하는 논문. 굳이 왜 대체하냐?

1. 임베딩의 표현력은 contrastive learning 방식으로 학습되었을 떄 더 높다.
  -> 임베딩 자체의 활용도가 높음.
2. 텍스트-이미지 임베딩 alignment 능력이 매우 유용함.

그러므로 저 두 능력을 유지되도록 lm-based embedder 튜닝하는 논문임.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251022_img0} style={{width: 500}} />
</div>

llm-based embedder 가 아니라 MLP 를 하나 붙여서 얘만 학습시킴.

1단계는 CLIP-text-encdoer 와 llm-based embedder 의 alignment 튜닝 작업.

2단계는 text-image alignment 가 맞도록 CLIP 방식으로 학습함.

## 4. [DSI-BENCH](https://arxiv.org/pdf/2510.18873)
### A BENCHMARK FOR DYNAMIC SPATIAL INTELLIGENCE

<div style={{textAlign: 'center'}}>
 <img src={blog_20251022_img1} style={{width: 500}} />
</div>


Observer 와 Object 가 동시에 움직이는 현실적인 3D 시나리오 데이터 벤치마크.

## 5. [VIDEO REASONING WITHOUT TRAINING](https://arxiv.org/pdf/2510.17045) `qualcomm`

퀄컴이 갑자기 왠 논문을. 

훈련 없이 Video reasoning 품질을 향상시키는 방법론. 한 가지 관찰에서 아이디어를 얻음.

모델의 토큰 생성 과정에서는 두 개의 큰 흐름이 있음. 
1. macro-exploration 단계 : 모델이 해답에 대한 불확실성을 느끼며 여러 대답을 검토하는 단계. 엔트로피가 점진적 증가.
2. micro-exploitation 단계 : 모델이 최종 대답에 대한 확신을 가지고 대답을 생성하는 단꼐. 엔트로피가 점진적 감소.

:::note:::
"We discover that more accurate models have an entropy peak that is both lower and delayed during Macro-Exploration and an Exploitation Phase that converges to a lower final entropy."
:::

좋은 모델일수록 macro-exploration 단계에서 엔트로피 피크가 낮고 늦게 나타나며, micro-exploitation 에서 최종적으로 더 낮은 엔트로피로 수렴함.

관찰 결과가 [SWIREASONGING](/docs/papers/y2025/oct/20251007#swireasoning-microsoft) 과도 관련이 있어보인다.

이를 바탕으로, LLM 의 토큰 생성 직전에 작은 trainable vector 를 추가한다. 이 trainable vector 를 controller 라고 부르겠음. 이 controller 는 토큰이 생성될떄마다 학습되면서 값이 업데이트됨.

학습에 사용되는 loss 는 
- entropy EMA 가 증가하는 추세일 때 -> entropy EMA 가 증가하도록 장려
- entropy EMA 가 감소하는 추세일 때 -> entropy EMA 가 감소하도록 장려

즉, 좋은 모델에서 보이는 추세를 잘 따라가도록 가이던스를 주는 controller 를 추가하는 거임.

훈련한 모델만큼 성능이 나오지는 않았지만, 학습 시간 등의 효율성을 극대화 시키면서 거의 훈련된 모델 성능을 따라잡았다고 함. 큰 장점으로 이야기한 것중 하나가 확장성. 복잡하지 않은 구조로 대부분의 모델에 쉽게 적용가능하다고 함.

## 6. [Extracting alignment data in open models](https://arxiv.org/pdf/2510.18554) `google`

open-source model 의 공개되지 않은 훈련 데이터를 뽑아낼 수 있다는 논문. 위험성 알리려는게 당연히 목표일거다.

open-source model 이 <|user|> 와 같은 시작 토큰을 post-train 단계에서만 도입된다는 범을 이용해서, 이 prefix 를 사용한 prompt 를 alignment data 와 유사한 텍스트를 생성하도록 유도함.

<|user|> -> 훈련 데이터를 줄줄 뱉는다는 말..

* Verbatim : 완벽히 똑같이 일치하는 복제한 문자열. (말그대로, 문자그대로)