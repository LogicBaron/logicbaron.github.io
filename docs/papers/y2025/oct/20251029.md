import blog_20251029_img0 from './asset/blog_20251029_img0.png';
import blog_20251029_img1 from './asset/blog_20251029_img1.png';
import blog_20251029_img2 from './asset/blog_20251029_img2.png';
import blog_20251029_img3 from './asset/blog_20251029_img3.png';

# 2025-10-29 papers review

## 1. [FunReason-MT Technical Report: Multi-Turn Function Callingg](https://huggingface.co/papers/2510.24448)

LLM 도구 multi-turn function calling 문제를 해결하기 위한 방법 제안.

matser 를 두는 방식. top-down 실행.

먼저 도구들의 dependency graph 그린다. 그 후 목표를 이루기위한 execution trace 를 구상. execution trace 를 추상화해서 어려운 쿼리를 구상. 이 과정은 **상위 레벨 연산 툴 합성** -> 상위 레벨 연산 툴로 풀 수 있는 상위 레벨 쿼리 구상. 마지막으로 오류 피드백. 각 과정이 의미 있는듯. 

## [Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs](https://huggingface.co/papers/2510.24514) `microsoft`   

화.. 똑똑하다...

MLLM 모델은 시각 요소 이해 능력은 뛰어나지만 visual reasoning (multimodal reasoning) 능력은 떨어짐. 이는 모델이 "상상력", 그러니까 이미지 기반 생각 능력이 부족해서 그럼. 사람은 이미지 관련 문제를 "상상" 해서 해결함. 예를 들어서 미로. 미로를 글로 생각해서 해결하는 사람이 있을까?

Latent sketchpad를 도입. native autoregressive reasoning process 내에서 textual reasoning과 visual latents 생성을 interleave. 

<div style={{textAlign: 'center'}}>
 <img src={blog_20251029_img0} style={{width: 500}} />
</div>

진짜 말그대로 visual latent 를 생성한다. 이 방식의 가장 큰 장점은 plug-and-play. 모듈 내부에 생성되는 것이 아니라 autoregressive 과정에서 이미지 latent 를 생성해서 사용하는 방식이기 때문에 MLLM 뒤에 붙이면 됨. 실제로 Qwen3 모델들에 붙여서 실험 진행함.

visual latent 를 디코딩할 수 있는 sketch decoder 도 학습시킴.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251029_img1} style={{width: 500}} />
</div>

학습은 backbone model 을 frozen 하고 진행됨.

## 2. [ATLAS](https://huggingface.co/papers/2510.22037) `google`
### ADAPTIVE TRANSFER SCALING LAWS FOR MULTILINGUAL PRETRAINING, FINETUNING, AND DECODING THE CURSE OF MULTILINGUALITY

multi-language 에도 scailing law 가 있음. curse of dimension 에 가깝나?

multi-language train 의 문제 중 하나인 **다국어 저주 (Curse of Multilinguality)**는 하나의 모델을 여러 언어로 동시에 학습(다국어 사전 학습)할 때 발생하는 성능 저하 현상을 의미합니다. 또한 언어간 전이 현상. 긍정적인 전이와 부정적인 전이가 전부 있어 예측하기 어렵닥.

본 논문은 이런 문제를 고려해서 multi-language train 에 있어서 scailing law 효과를 검증함.

일단 언어수가 늘어나면 모델 크기도 확장시켜야 한다. 특히 성능 유지에 있어서는 **데이터 크기보다 모델 크기 증가**가 더 큰 이득을 가져옵니다.

multi-language 이슈는 언어 수가 증가할 때마다 모델 크기와 데이터 크기가 **지수적**으로 확장되어야 한다고 함.

## 3. [Game-TARS](https://huggingface.co/papers/2510.23691) `bytedance`
### Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents

바이트 댄스의 게임 논문. 바이트 댄스가 영상AI를 엄청 연구하는 만큼 게임 에이전트 쪽 연구가 합쳐지면 시너지가 엄청날 것이라고 생각함.

통합적인 게임 에이전트에 대한 논문. 기존 게임 에이전트 연구들은 한정된 행동에 반응하는 수준이었지만 전반적인 마우스 키보드 입력에 대해 반응할수 있는 게임 에이전트를 학습시킴.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251029_img2} style={{width: 500}} />
</div>


## 4. [From Spatial to Actions](https://huggingface.co/papers/2510.17439) `bytedance`
### Grounding Vision-Language-Action Model in Spatial Foundation Priors

- 기존 VLA(Vision-Language-Action) 로봇 모델은 3D 실제 환경에서 작동함에도 2D 인코더 기반으로 구축되어 3D 공간 추론(Spatial Reasoning)의 공백이 발생
- FALCON은 풍부한 3D 공간 정보를 **액션 헤드(Action Head)**에 직접 주입
- FALCON은 세 가지 시뮬레이션 벤치마크 (CALVIN, SimplerEnv) 및 11가지 실제 태스크에서 일관되게 SOTA 성능을 달성

<div style={{textAlign: 'center'}}>
 <img src={blog_20251029_img3} style={{width: 500}} />
</div>