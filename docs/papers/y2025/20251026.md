


# 2025-10-26 papers review

## 1. [SAKE](https://arxiv.org/pdf/2510.16917)
### Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models

오디어 기반 속성 벤치마크 구축.

## 2. [ARC-Encoder](https://arxiv.org/pdf/2510.20535)
### learning compressed text representations for large language models

기존 컨텍스트 엔지니어링 방식의 기조는 컨텍스트를 일단은 LLM input 으로 활용하는 방식.

시간 복잡도는 $O(N^2)$. 해당 논문은 압축률에 해당하는 만큼의 컨텍스트는 한번에 처리하지 않고 따로 처리한뒤 average pooling 해도 괜찮다고 함.

예)
- 20개 컨텍스트에 압축률이 4라
- 4개씩 총 5개의 그룹 생성.
- 4개 그룹에 대해 평균 임베딩 생성.
- 5개를 이용해서 그룹 임베딩 생성 후 return.

이런 방식의 동작이 가능해졌습니다.