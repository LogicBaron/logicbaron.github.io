import blog_20251026_img0 from './asset/blog_20251026_img0.png';

# 2025-10-26 papers review

## 1. [SAKE](https://arxiv.org/pdf/2510.16917)
### Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models

오디어 기반 속성 벤치마크 구축.

## 2. [ARC-Encoder](https://arxiv.org/pdf/2510.20535)
### learning compressed text representations for large language models

기존 컨텍스트 엔지니어링 방식의 기조는 컨텍스트를 일단은 LLM input 으로 활용하는 방식.

시간 복잡도는 $O(N^2)$. 해당 논문은 압축률에 해당하는 만큼의 컨텍스트는 한번에 처리하지 않고 따로 처리한뒤 average pooling 해도 괜찮다고 함.

예)
- 20개 컨텍스트에 압축률이 4라
- 4개씩 총 5개의 그룹 생성.
- 4개 그룹에 대해 평균 임베딩 생성.
- 5개를 이용해서 그룹 임베딩 생성 후 return.

이런 방식의 동작이 가능해졌습니다.

## 3. [RECALL](https://huggingface.co/papers/2510.20479)
### REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging

음.. 모델 내부 상태를 해석해 모델 신뢰도로 사용하려는 논문. 근데 이전 논문을 읽다보니 결국 근본적인 문제 해결은 모델 내부 상태와 무관하다는 생각이 든다.

뭐 예를 들어 현재의 지구인에게 "5차원에서 3차원 다이빙하기 vs 6차원에서 4차원 다이빙하기" 라고 하면 누가 정확히 말해줄까. 가장 똑똑한 사람이라도 사유의 결과일것이다. 아무도 알수없단 거지.

알아버린 이후로 현타가.

## 4. [Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost](https://huggingface.co/papers/2510.20780)

피곤하것도 맞는데 너무 논쟁적이다. 그래서 무지는 선한가?


## 5. [Visual Diffusion Models are Geometric Solvers](https://huggingface.co/papers/2510.21697)

<div style={{textAlign: 'center'}}>
 <img src={blog_20251026_img1} style={{width: 500}} />
</div>

Visual Diffusion Model. 솔직히 명확하게 논리적 흐름을 잘 캐치못한 논문이나, LLM 내부 동작에 대한 많은 통찰을 제공한다생각.

프린키피아를 읽어봤는가? 우리는 수식 또는 일반적인 그림을 그려서 푸는 문제들을 원 위에서 모두 해결한다. 경이롭고, 너무 어렵다. 이 논문은 기하학을 재구성해서 생성 문제로 풀어버리는데, 비슷한 느낌임. 

그리고 그 결과 모델의 성능이 훨씬 좋았다. 우연아닐까? 우리의 논리는 애초에 우연의 중첩에 의해 귀납적으로 쌓인다. 무시할 수는 없지만 논문은 귀납적 가능성을 꽤 많이 배제한다. 우리의 태양 대신 갑자기 칠면조 샷건이 내일 하늘에 떠오를 확률은 거의 없으니까.

그럼 드는 생각은?

이 논문의 수학은 적어도 그런 톡톡 튀는 관점이 보인다. 규칙에 대해 생각해보는 것도 좋을 듯하다.