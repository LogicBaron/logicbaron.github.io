---
id: holdout
sidebar_position: 1
---
# Holdout

holdout 기법은 일반적으로 사용하는 전체 데이터셑을 일정 비율로 train data, test data 로 나누는 방법입니다.

일반적으로 **stratified random sampling** 을 활용합니다. 단순한 random sampling 에 비해 imbalanced data에 대해 일반적으로 긍정적인 성능을 보여준다는 사실이 확인되었다고 합니다. 

다만, 데이터의 규모가 충분히 크고 imbalance가 심하지 않다면 random sampling을 사용해도 큰 상관이 없습니다.

holdout 방식은 깨끗한 데이터에 대해서는 좋은 sampling 방식이 될 수 있지만 데이터가 깨끗하지 않은 경우에는 적절하지 않습니다. 

무엇보다 평가 데이터에도 노이즈가 섞여서 적절하지 않은 평가 기준이 만들어집니다.

또한, 훈련 데이터에도 평가 데이터와 비슷한 노이즈가 존재하므로 overfitting 등의 영향을 제대로 파악하지 못하고, 오히려 노이즈가 있는 상황에서 더 좋은 지표가 관찰될 수 있습니다.

그렇지만 적절한 학습 데이터와 평가 데이터를 구축하는 것은 실제로는 리소스가 매우 많이 소모되는 일이므로 적절한 샘플링 방법을 통해서 이 과정의 효율성을 높일 필요가 있습니다.