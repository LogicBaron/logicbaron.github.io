---
id: lattice
sidebar_position: 0
---

import blog_2025101802_img0 from './asset/blog_2025101802_img0.png';

# LLM-GUIDED HIERARCHICAL RETRIEVAL `google`

구글이 검색에서 가지고 있던 노하우를 LLM 에 잘 녹여냈다고 생각이 되는 논문이다.

논문의 핵심은 문서 검색을 단순 인덱스 방식이 아니라 hierachical 방식으로 접근했다는 점. 이로 인해서 로그 시간 효율성을 달성했고, 초기 검색 성능을 보장하고 LLM 노이즈에 더욱 강건해짐.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251018_img0} style={{width: 500}} />
</div>

언제나 데이터 구축 방식은 중요하다. 구글은 트리를 어떻게 구축했을까?

1. bottom-up
  - 기존 트리 구조가 없는 단순 문서 집합에서 사용.
  - 문서 임베딩이 비슷한 것들끼리 모으고, 문서 집합의 요약을 생성하고 요약이 비슷한것끼리 묶는 방식.
  - 최상위 문서 집합 개수가 M개 미만이 될떄까지 반복한다.
2. top-down
  - 기존 트리구조가 있는 경우에 사용.
  - 문서 집합을 주고, 문서 집합을 K개의 새로운 문서 집합으로 나누어달라고 요구.
  - 여전히 크기가 큰 문서집합에 대해서는 이 과정을 반복.
  - 근데 이거 해보니까 잘 안되던데 테크닉이 엄청 들어갔을 것 같다.

이렇게 구축한 검색 트리를 탐색해서 문서를 검색함. beam search 가 도입되는데 이 과정에서 beam 과 beam 을 LLM 이 비교하는게 매우 중요하다고 함.

검색 성능은 zero-shot 으로 BM25와 같은 zero-shot 모델은 능가하고, 가끔 튜닝된 SOTA 모델 성능도 이긴다고 나옴.

* 검색 효율성 외 트리의 장점 : 단순 키워드나 semantic similarity (문맥 유사도) 로는 찾을 수 없는 문서가 많다. 예를 등러 특정 정리를 이용해야 풀 수 있는 수학 문제의 경우, 단순 문서 검색으로는 해당 정리를 찾기 매우 어려움. 그런데 충분한 관련 문서를 모은 뒤 요약한다면 탐색의 단초를 잡는데 도움이 된다.

### calibrated latent relavance score

중요하다고 생각되는 개념.

문서의 연관도 점수는 분명 특정한 값을 가질텐데, LLM 은 관련 검색 slate 를 어떻게 구성하느냐에 따라 다른 연관도 점수를 내놓는다. 이를 해결하기 위해서, LLM 의 답변에서 보여지는 연관도가 진짜 점수, 슬레이트 구성에 따른 편향의 함수라고 가정함.

$$
$s_{v}^{i} \approx a \cdot \hat{s}_{v} + b^{i}$
$$

많은 관찰 결과를 바탕으로 진짜 점수를 찾아간다고 이해하면 됨. 좋은 아이디어라고 생각됨. 연산량만 문제 없다면. 논문에서는 20번 탐색후에 종료했다고 함.

Markdown

#### LATTICE 계산 과정 예시: Calibrated Latent Relevance Score

**검색어:** "3D 그래픽스에서 쿼터니언(quaternion)을 사용한 회전 방법"

---

##### **1. 초기 상태: 검색 시작 🚀**

* **검색 트리**: 문서들이 '그래픽스', '물리학', '역사'라는 세 가지 큰 주제로 묶여 있음.
* **프론티어(Frontier)**: 탐색 후보지를 담는 우선순위 큐.
    * 초기 상태: `[ {노드: '루트', 경로_점수: 1.0} ]`

---

##### **2. 1차 탐색 (Iteration 1) 🧭**

1.  **노드 선택**: 프론티어에서 **'루트' 노드**를 꺼냄.
2.  **슬레이트(Slate) 구성**: 루트의 자식 노드인 '그래픽스', '물리학', '역사'의 요약문을 평가 목록으로 구성.
3.  **LLM 평가**: 검색 LLM이 슬레이트를 평가하고 국소 점수(local scores)를 반환.
    * **LLM 출력**: `[ {노드: '그래픽스', 점수: 0.9}, {노드: '물리학', 점수: 0.4}, {노드: '역사', 점수: 0.1} ]`
4.  **잠재 점수(Latent Score) 추정**: 첫 평가이므로 LLM 점수를 그대로 잠재 점수의 초기 추정치로 사용.
    * `잠재_점수['그래픽스'] = 0.9`
    * `잠재_점수['물리학'] = 0.4`
    * `잠재_점수['역사'] = 0.1`
5.  **경로 관련성 점수(Path Relevance Score) 업데이트**:
    * `경로_점수['그래픽스']` = 0.5 * (부모 점수 1.0) + 0.5 * (잠재 점수 0.9) = **0.95**
    * `경로_점수['물리학']` = 0.5 * 1.0 + 0.5 * 0.4 = **0.70**
    * `경로_점수['역사']` = 0.5 * 1.0 + 0.5 * 0.1 = **0.55**
6.  **프론티어 업데이트**:
    * 현재 프론티어: `[ {노드: '그래픽스', 경로_점수: 0.95}, {노드: '물리학', 경로_점수: 0.70}, {노드: '역사', 경로_점수: 0.55} ]`

---

##### **3. 2차 탐색 (Iteration 2) - 보정(Calibration)의 시작 ✨**

1.  **노드 선택**: 프론티어에서 가장 점수가 높은 **'그래픽스' 노드**를 꺼냄.
2.  **슬레이트 구성**:
    * '그래픽스'의 자식 노드: '3D 렌더링', 'UI 디자인'
    * **보정용 노드**: '그래픽스'의 형제 노드 중 가장 점수가 높았던 '물리학'을 포함.
    * 최종 슬레이트: `['3D 렌더링', 'UI 디자인', '물리학']`
3.  **LLM 평가**: LLM이 새로운 맥락에서 슬레이트를 다시 평가.
    * **LLM 출력**: `[ {노드: '3D 렌더링', 점수: 0.95}, {노드: 'UI 디자인', 점수: 0.3}, {노드: '물리학', 점수: 0.5} ]`
4.  **잠재 점수(Latent Score) 추정 (핵심 단계)**:
    * '물리학' 노드는 1차 평가에서 `0.4`, 2차 평가에서 `0.5`를 받음.
    * 시스템은 이 점수 차이가 각 평가의 맥락(함께 제시된 다른 노드들) 때문에 발생한 편향(bias)이라고 가정.
    * 모든 관찰 기록(`[0.4, 0.5]`)을 가장 잘 설명하는 **보이지 않는 '진짜 관련성 점수'(latent relevance score)**를 통계적으로 역추산함.
    * **추정 결과 (예시)**: `잠재_점수['물리학']`이 `0.45`로 **보정됨**.
        * `잠재_점수['3D 렌더링'] = 0.95`
        * `잠재_점수['UI 디자인'] = 0.3`
5.  **경로 관련성 점수 업데이트**: **보정된 잠재 점수**를 사용하여 경로 점수를 계산.
    * `경로_점수['3D 렌더링']` = 0.5 * (부모 '그래픽스' 점수 0.95) + 0.5 * (잠재 점수 0.95) = **0.95**
    * `경로_점수['UI 디자인']` = 0.5 * 0.95 + 0.5 * 0.3 = **0.625**
6.  **프론티어 업데이트**:
    * 현재 프론티어: `[ {노드: '3D 렌더링', 경로_점수: 0.95}, {노드: '물리학', 경로_점수: 0.70}, {노드: 'UI 디자인', 경로_점수: 0.625}, {노드: '역사', 경로_점수: 0.55} ]`

---

##### **4. 이후 과정 및 종료 🏁**

* 이후에도 가장 점수가 높은 노드를 계속 탐색하며, 평가 기록이 쌓일수록 모든 노드의 잠재 관련성 점수는 더욱 정교하게 보정됩니다.
* 미리 정해진 반복 횟수(예: 20회)에 도달하면 탐색을 종료하고, 최종적으로 발견된 문서(leaf nodes)들을 경로 관련성 점수 순으로 정렬하여 결과를 반환합니다.