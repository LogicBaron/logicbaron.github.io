"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[4635],{6478:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>o,contentTitle:()=>d,default:()=>a,frontMatter:()=>s,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"concepts/largemodel/RLHF/RLHF","title":"Concept","description":"GPT-4o \uc758 \uc124\uba85.","source":"@site/docs/concepts/largemodel/RLHF/concept.md","sourceDirName":"concepts/largemodel/RLHF","slug":"/concepts/largemodel/RLHF/RLHF","permalink":"/docs/concepts/largemodel/RLHF/RLHF","draft":false,"unlisted":false,"editUrl":"https://github.com/logicbaron/logicbaron.github.io/tree/dev/docs/concepts/largemodel/RLHF/concept.md","tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"id":"RLHF","sidebar_position":0}}');var i=t(4848),c=t(8453);const s={id:"RLHF",sidebar_position:0},d="Concept",o={},l=[];function p(n){const e={h1:"h1",header:"header",li:"li",ol:"ol",p:"p",...(0,c.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"concept",children:"Concept"})}),"\n",(0,i.jsx)(e.p,{children:"GPT-4o \uc758 \uc124\uba85."}),"\n",(0,i.jsx)(e.p,{children:"\uc88b\uc544, RLHF (Reinforcement Learning from Human Feedback), \uc81c\ub300\ub85c \uc804\uccb4 \uad6c\uc870\ubd80\ud130 \uae54\ub054\ud558\uac8c \uc815\ub9ac\ud574\uc904\uac8c."}),"\n",(0,i.jsx)(e.p,{children:"\u2e3b"}),"\n",(0,i.jsx)(e.p,{children:"\u2705 RLHF (Reinforcement Learning from Human Feedback)\ub780?"}),"\n",(0,i.jsx)(e.p,{children:"\uc0ac\ub78c\uc758 \ud53c\ub4dc\ubc31\uc744 \uc774\uc6a9\ud574 \ubaa8\ub378(\ud2b9\ud788 LLM)\uc744 \ud6c8\ub828\ud558\ub294 \uac15\ud654\ud559\uc2b5 \ubc29\ubc95\uc774\uc57c."}),"\n",(0,i.jsx)(e.p,{children:"\ud575\uc2ec \uc544\uc774\ub514\uc5b4:\n\u2022\t\uc778\uac04\uc774 \uc9c1\uc811 \uc88b\uc740 \uc751\ub2f5/\ud589\ub3d9\uc744 \ud3c9\uac00\ud558\uac70\ub098,\n\u2022\t\uc778\uac04\uc774 \ub9cc\ub4e4\uc5b4\uc900 \uc120\ud638\ub3c4(preference) \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud574\uc11c\n\u2022\t\ubaa8\ub378\uc774 \ub354 \uc778\uac04 \uce5c\ud654\uc801\uc778 \ud589\ub3d9\uc744 \ud558\ub3c4\ub85d \ud559\uc2b5\uc2dc\ud0a4\ub294 \uac83."}),"\n",(0,i.jsx)(e.p,{children:"\u2e3b"}),"\n",(0,i.jsx)(e.p,{children:"\ud83c\udfaf \uc65c RLHF\ub97c \uc4f8\uae4c?\n\u2022\tGPT\ub098 LLM \uac19\uc740 \ubaa8\ub378\uc740 \ub2e8\uc21c\ud55c \uc5b8\uc5b4 \uc608\uce21\ub9cc\uc73c\ub85c\ub294\n\uc0ac\ub78c\uc774 \uc6d0\ud558\ub294 \ub2f5\ubcc0\uc744 \uc81c\ub300\ub85c \ubabb\ud568.\n\u2022\t\uadf8\ub0e5 Language Modeling\ub9cc \ud558\uba74:\n\u2022\t\ubd80\uc815\ud655\ud558\uac70\ub098,\n\u2022\t\ube44\uc724\ub9ac\uc801\uc774\uac70\ub098,\n\u2022\t\ud130\ubb34\ub2c8\uc5c6\ub294 \ub2f5\ubcc0\uc774 \ub098\uc62c \uc218 \uc788\uc74c.\n\u2022\t\uadf8\ub798\uc11c \uc0ac\ub78c\uc758 \u201c\uc774\uac8c \uc88b\uc740 \ub2f5\ubcc0\uc774\uc57c\u201d\ub77c\ub294 \ud53c\ub4dc\ubc31\uc744 \uc368\uc11c \ubaa8\ub378 \ucd9c\ub825\uc744 \uc81c\uc5b4\ud558\ub824\ub294 \uac70\uc57c."}),"\n",(0,i.jsx)(e.p,{children:"\u2e3b"}),"\n",(0,i.jsx)(e.p,{children:"\ud83d\ude80 RLHF \uc804\uccb4 \uacfc\uc815 (3\ub2e8\uacc4 \uad6c\uc870)"}),"\n",(0,i.jsx)(e.p,{children:"\ub2e8\uacc4\t\uc124\uba85\n1\ub2e8\uacc4\tSupervised Fine-Tuning (SFT)\uc6b0\uc120 \uc0ac\ub78c \uc791\uc131 \ub2f5\ubcc0\uc744 \ubaa8\uc544\uc11c \ubaa8\ub378\uc744 \uc815\uc2dd \uc9c0\ub3c4\ud559\uc2b5 \uc2dc\ud0b4\n2\ub2e8\uacc4\tReward Model Training (RM)\uc0ac\ub78c\uc774 \uc120\ud638\ud558\ub294 \uc751\ub2f5\uc30d \ub370\uc774\ud130\ub97c \ubaa8\uc544\uc11c \ubcf4\uc0c1\ubaa8\ub378(Reward Model)\uc744 \ud559\uc2b5\n3\ub2e8\uacc4\tReinforcement Learning (RL)Reward Model\uc744 \uc774\uc6a9\ud574\uc11c \ubaa8\ub378\uc744 PPO \uac19\uc740 \uac15\ud654\ud559\uc2b5\uc73c\ub85c \ud29c\ub2dd"}),"\n",(0,i.jsx)(e.p,{children:"\u2e3b"}),"\n",(0,i.jsx)(e.p,{children:"\ud83d\udcc8 \uc870\uae08 \ub354 \uc790\uc138\ud788 \ub4e4\uc5b4\uac00\uba74"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:"SFT (Supervised Fine-Tuning)\n\u2022\t\ub300\uaddc\ubaa8\ub85c \uc778\uac04\uc774 \uc791\uc131\ud55c \uc9c8\ubb38-\ub2f5\ubcc0 \uc30d\uc744 \ud559\uc2b5\n\u2022\t\uc774\uac78\ub85c \ucd08\uae30 \uc778\uac04 \uce5c\ud654\uc131 \ud655\ubcf4"}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:"Reward Model (RM) \ud559\uc2b5\n\u2022\t\uac19\uc740 \uc9c8\ubb38\uc5d0 \ub300\ud55c \ub450 \uac00\uc9c0 \ub2f5\ubcc0\uc744 \ubaa8\ub378\uc774 \uc0dd\uc131\n\u2022\t\uc778\uac04\uc774 \u201cA vs B \uc911 \ubb34\uc5c7\uc774 \ub354 \uc88b\uc544?\u201d \ub77c\uace0 \ud3c9\uac00\n\u2022\t\uc774\uac78 \ubaa8\uc544\uc11c \ubcf4\uc0c1\ud568\uc218\ub97c \ud559\uc2b5\n\u2022\tReward Model\uc740 \uc751\ub2f5\uc5d0 \uc810\uc218\ub97c \ub9e4\uae38 \uc218 \uc788\uac8c \ub428"}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:"PPO (Proximal Policy Optimization)\n\u2022\t\uae30\uc874 \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \uc751\ub2f5\uc5d0 \ub300\ud574 Reward Model\uc774 \ubcf4\uc0c1\uc744 \uc90c\n\u2022\t\ubcf4\uc0c1\uc744 \uadf9\ub300\ud654\ud558\ub3c4\ub85d Policy(\ubaa8\ub378)\ub97c \uc5c5\ub370\uc774\ud2b8\n\u2022\t\uc774 \uacfc\uc815\uc744 \ubc18\ubcf5\ud574\uc11c \ubaa8\ub378\uc744 \uc810\uc810 \ub354 \u201c\uc0ac\ub78c \ucde8\ud5a5\u201d\uc5d0 \ub9de\uac8c \uc870\uc815"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"\u2e3b"}),"\n",(0,i.jsx)(e.p,{children:"\ud83e\udde0 \ud575\uc2ec \ud2b9\uc9d5\n\u2022\tHuman Feedback\uc774 \u201c\uc9c4\uc9dc \ub2f5\u201d\uc744 \uc9c1\uc811 \uc8fc\ub294 \uac8c \uc544\ub2c8\ub77c\n\u2192 \uc88b\ub2e4/\ub098\uc058\ub2e4\ub294 \uc0c1\ub300\uc801 \uc2e0\ud638\ub97c \uc8fc\ub294 \uac70\uc57c (preference-based)\n\u2022\tDirect Supervised Signal \uc5c6\uc774\ub3c4 \ubaa8\ub378\uc744 \uac1c\uc120 \uac00\ub2a5\n\u2022\t\ud2b9\ud788 LLM(\ub300\ud615 \uc5b8\uc5b4\ubaa8\ub378) \uac19\uc740 open-ended output\uc5d0\uc11c\ub294 \uad49\uc7a5\ud788 \ud6a8\uacfc\uc801"}),"\n",(0,i.jsx)(e.p,{children:"\u2e3b"}),"\n",(0,i.jsx)(e.p,{children:"\ud83e\udde9 \uadf8\ub9bc\uc73c\ub85c \ubcf4\uba74"}),"\n",(0,i.jsx)(e.p,{children:"[Pretrained LM]\n\u2193 (Supervised Fine-Tuning)\n[SFT \ubaa8\ub378]\n\u2193 (Human Preferences \uc218\uc9d1)\n[Reward Model]\n\u2193 (PPO \uac15\ud654\ud559\uc2b5)\n[\ucd5c\uc885 RLHF \ubaa8\ub378]"}),"\n",(0,i.jsx)(e.p,{children:"\u2e3b"}),"\n",(0,i.jsx)(e.p,{children:"\ud83d\udce6 \uc694\uc57d"}),"\n",(0,i.jsx)(e.p,{children:"\ud0a4\ud3ec\uc778\ud2b8\t\uc124\uba85\n\ubaa9\uc801\t\ubaa8\ub378\uc744 \uc778\uac04 \uc120\ud638\uc5d0 \ub9de\ucdb0 \uc815\uc81c\n\ubc29\ubc95\t\uc778\uac04 \uc120\ud638 \ub370\uc774\ud130 + \uac15\ud654\ud559\uc2b5\n\uacfc\uc815\tSFT \u2192 Reward Model \u2192 PPO \ucd5c\uc801\ud654\n\ud6a8\uacfc\t\ub354 \uc548\uc804\ud558\uace0 \uc77c\uad00\ub41c \ubaa8\ub378 \uc751\ub2f5 \uc0dd\uc131"}),"\n",(0,i.jsx)(e.p,{children:"\u2e3b"}),"\n",(0,i.jsx)(e.p,{children:"\ud83d\udcda RLHF \uc2e4\uc81c \uc801\uc6a9 \uc608\uc2dc\n\u2022\tGPT-3.5, GPT-4 \ud559\uc2b5\uc5d0 RLHF \uc801\uc6a9\n\u2022\tInstructGPT (GPT-3 + RLHF\ub85c \ub9cc\ub4e4\uc5b4\uc9c4 \ub300\ud3ed \ud5a5\uc0c1 \ubc84\uc804)\n\u2022\tAnthropic\uc758 Claude \ubaa8\ub378\ub3c4 RLHF \uae30\ubc18\n\u2022\tOpenAI\ub294 RLHF \uc5c6\uc73c\uba74 \ubaa8\ub378\uc744 \uc808\ub300 \uc11c\ube44\uc2a4 \uc548 \ud568 (\uc548\uc804\uc131 \ub54c\ubb38)"}),"\n",(0,i.jsx)(e.p,{children:"\u2e3b"}),"\n",(0,i.jsx)(e.p,{children:"\ud83d\ude80 \ucd94\uac00\ub85c \uc54c\ub824\uc904 \uc218 \uc788\ub294 \uac83\n\u2022\tRLHF \uc138\ubd80 \uc54c\uace0\ub9ac\uc998 (PPO vs DPO \ucc28\uc774)\n\u2022\tRLHF\ub97c \ub118\uc5b4 RLAIF (RL from AI Feedback) \ub4f1\uc7a5\ud55c \uc774\uc720\n\u2022\tRLHF \ub370\uc774\ud130\uc14b \uc218\uc9d1 \uc2e4\uc81c \ubc29\ubc95\n\u2022\tRLHF \ucf54\ub4dc \uc608\uc81c (PPO+transformers)"}),"\n",(0,i.jsx)(e.p,{children:"\u2e3b"}),"\n",(0,i.jsx)(e.p,{children:"\ud544\uc694\ud558\uba74 RLHF \ud559\uc2b5 \ud30c\uc774\ud504\ub77c\uc778 \uc544\ud0a4\ud14d\ucc98\ub098,\n\u201c\uc65c PPO\ub97c \uc4f0\ub294\uc9c0?\u201d \uac19\uc740 \uc2ec\ud654\ub3c4 \uac08 \uc218 \uc788\uc5b4."}),"\n",(0,i.jsx)(e.p,{children:"\uc880 \ub354 \uae4a\uac8c \ub4e4\uc5b4\uac00\ubcfc\uae4c? \ud83d\udd25\n(\uc608\ub97c \ub4e4\uba74 \u201cDPO(Direct Preference Optimization)\u201c\ub791 RLHF \ube44\uad50 \uac19\uc740 \uac83\ub3c4 \uc788\uc74c)"})]})}function a(n={}){const{wrapper:e}={...(0,c.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(p,{...n})}):p(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>s,x:()=>d});var r=t(6540);const i={},c=r.createContext(i);function s(n){const e=r.useContext(c);return r.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function d(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:s(n.components),r.createElement(c.Provider,{value:e},n.children)}}}]);