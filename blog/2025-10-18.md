
import blog_20251018_img0 from './asset/blog_20251018_img0.png';
import blog_20251018_img1 from './asset/blog_20251018_img1.png';
import blog_20251018_img2 from './asset/blog_20251018_img2.png';

# 10-18 papers summary

논문이 꽤 많이 쏟아짐.

## 1. [PaddleOCR-VL](https://huggingface.co/PaddlePaddle/PaddleOCR-VL)
### Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model

복잡한 문서를 마크다운 혹은 json 으로 구조화하여 저장하는 것은 꽤 어려운 과제임. 다양한 영역에서 필요성이 확실하지만 매우 복잡한 문제.

PaddleOCR 이 이 분야에서 꽤 유명했는데 신규 모델이 나옴. 기존 문서 파싱 방식은 VLM 을 바로 적용하기 어려웠음. 1) 계산 비용 이슈. 2) hallucination 과 문서 복잡성.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251018_img0} style={{width: 500}} />
</div>

두 단계로 나누어서 문서 파싱과 OCR 분석을 진행하여 문서를 체계화함. 작은 레이아웃 분석 모델 -> 작은 VLM 모델.
  - PP-DocLayoutV2 : 레이아웃 붑ㄴ석 -> PaddleOCR-VL-0.9B VLM : 문서 요소 분석

<div style={{textAlign: 'center'}}>
 <img src={blog_20251018_img1} style={{width: 500}} />
</div>

문서 파싱에서 핵심 중 하나는 원본 해상도 유지임. PaddleOCR 은 파싱된 각 요소의 원본 이미지를 사용해서 VLM input token 으로 바꿔주는 구조를 채택. 또한 요소별 instruction 도 따로 지정후 한번에 VLM 의 input 으로 사용.

## 2. Qwen3Guard Technical Report

안전 가드레일 모델의 분류 체계에 두 가지 변화. 1) 안전/위험 이진 분류 -> 안전/애매/위험 삼진 분류 체계. 2) 토큰 단위 stream 분류. 토큰 생성 과정에서 실시간으로 분석 가능.

구조적으로 주목할만한 점은 데이터 구축 과정. 데이터 구축 과정이라고 하지만 industry 레벨에서는 안전 분류 모델로 학습할 수 있어 보임.

**Strict (엄격한) 모델**: '위험(Unsafe)' 샘플의 비율을 높여 학습시킵니다. 이 모델은 조금이라도 의심스러우면 '위험(Unsafe)'으로 판단하는 경향이 강해집니다. 

**Loose (느슨한) 모델**: '안전(safe)' 샘플의 비율을 높여 학습시킵니다. 이 모델은 비교적 관대하게 '안전(Safe)'으로 판단하는 경향이 생깁니다.

두 모델의 결과를 합쳐서 사용함. 예를 들어, 둘 다 safe 이면 최종 safe, 둘이 서로 다른 라벨이면 controversal.

## 3. LLM models don't know what they know.

LLM 모델이 내재적으로 자신이 아는 것과 모르는 것을 제대로 구분하지 못한다는 논문. 

"주제와 연관 없는 환각" 의 경우 모델 내부 hidden state 에서 뚜렷하게 구분되지만, "주제와 관련된 환각"은 모델 내부에서 거의 구분할 수 없다.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251018_img2} style={{width: 500}} />
</div>

LLM 구조, attention 구조는 지식의 옳고그름을 판단하는 논리적인 mechnism 을 내부적으로 갖출 수 없다. 오로지 주제와의 연관성을 바탕으로 지식을 회상할 뿐이라는 결론을 내린다.

hallucination 을 해결하려는 노력 중 한가지는 I don't know 학습이다. 모르면 모른다고 대답하도록 학습하는 것인데 논문의 주장을 인정한다면 이 튜닝은 크게 의미가 없다. 주제와 관련없는 환각은 모델을 분석해서 구분할 수 있고, 주제와 관련있는 환각은 학습될 수 없다.

이런 의문이 들었다. 사람의 의식은 일종의 논리 기반의 지식 그래프를 가지고 있을까? 사실 사람의 의식도 위 논문과 똑같이 동작하지 않을까. 사람도 자신이 뭘 모르는지 알기 어려우니까.

## 4. [LEARNING AN IMAGE EDITING MODEL WITHOUT IMAGE EDITING PAIRS](https://arxiv.org/pdf/2510.14978)

대규모 데이터 없이 이미지 편집 모델을 학습시키기 위해 노력한 논문. 논문에서는 데이터 구축 과정이 아닌 모델 학습 패러다임이라고 했지만, 논문을 읽어보면 데이터 구축 과정으로 사용하는 게 더 좋지 않을까하는 생각이 든다.

이미지와 prompt 를 가지고 편집된 이미지를 생성한 후, VLM 을 이용해서 피드백을 함.

피드백의 주안점은, 1) 편집 지시가 잘 이행되었는가? 그리고 2) 유지해야하는 원본 이미지의 디테일을 잘 유지하고있는가? 이다.

