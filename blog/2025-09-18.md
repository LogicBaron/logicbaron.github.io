# 논문 정리

읽어서 정리 못할 것 같아서 GPT 사용

## 1. Measuring Epistemic Humility in Multimodal Large Language Models

https://arxiv.org/abs/2509.09658

epsitemic humility : 인지적 겸손 -> 모르는 것을 모른다고 하는 능력. calibration.

- HumbleBench라는 새로운 멀티모달 대형 언어 모델(MLLM)의 평가 벤치마크를 제안하며, 보기 중에 정답이 없을 때 “None of the above (NOTA)”을 고를 수 있는지를 평가하여 인식 정확도뿐 아니라 **오답 거부능력(epistemic humility)**을 측정. 
- 벤치마크는 객체, 관계, 속성(attribute) 세 가지 유형의 환각(hallucination)을 다루며, 약 22,831개의 다지선다형(multiple-choice) 질문으로 구성됨. 
- 기존 최신 MLLMs를 시험한 결과, 정답이 “None of the above”인 경우 정확도가 매우 낮았고, 모델 규모가 크다고 해서 무조건 성능이 더 좋지는 않으며, reasoning-fine-tune된 모델들도 환각 회피면에서 일관되게 우수하지 않다는 중요한 발견이 나옴.