# 논문 정리

읽어서 정리 못할 것 같아서 GPT 사용

## 1. Measuring Epistemic Humility in Multimodal Large Language Models

https://arxiv.org/abs/2509.09658

epsitemic humility : 인지적 겸손 -> 모르는 것을 모른다고 하는 능력. calibration.

- HumbleBench라는 새로운 멀티모달 대형 언어 모델(MLLM)의 평가 벤치마크를 제안하며, 보기 중에 정답이 없을 때 “None of the above (NOTA)”을 고를 수 있는지를 평가하여 인식 정확도뿐 아니라 **오답 거부능력(epistemic humility)**을 측정. 
- 벤치마크는 객체, 관계, 속성(attribute) 세 가지 유형의 환각(hallucination)을 다루며, 약 22,831개의 다지선다형(multiple-choice) 질문으로 구성됨. 
- 기존 최신 MLLMs를 시험한 결과, 정답이 “None of the above”인 경우 정확도가 매우 낮았고, 모델 규모가 크다고 해서 무조건 성능이 더 좋지는 않으며, reasoning-fine-tune된 모델들도 환각 회피면에서 일관되게 우수하지 않다는 중요한 발견이 나옴.

## 2.Lost in Embeddings: Information Loss in Vision–Language Models

VLM 에서 비전 인코더 출력을 언어 임베딩 공간으로 투영하는 connector 가 정보 손실을 일으킬 수 있음. 이로 인한 영향과 해결방법이 본격적으로 논의된 적은 별로없음. 이 논문은 connector 로 인한 정보 손실을 정량적으로 측정하고 그 영향을 확인함.

논문에서는 k-NN overlap ratio, 그리고 embedding reconstruction 방식을 제안함.

k-NN overlap ratio 방식은 connector 통과 전후의 k-nn 을 확인함. 투영 후 보존율은 50~60% 수준. retrieval 성능 도 투영후 전반적으로 하락. 임베딩 공간 상에서의 구조적인 왜곡.

reconstruction 과정에서도 정보 손실이 꽤 많이 이루어진다고 확인됨. reconstruction model 크기를 늘려도 성능 개선은 제한적이었다고 함. pacth-level 의 국소적인 정보 손실.

connector 는 구조적/세부적 시각 정보를 상당히 잃는다!
