
import blog_2025101802_img0 from './asset/blog_2025101802_img0.png';

# 10-18 papers summary - big tech

읽을 논문이 많아서 빅 테크 기업 논문은 따로 가져와봤다. 내가 투자한 회사는 무슨 연구하고 있나?

## 1. LLM-GUIDED HIERARCHICAL RETRIEVAL `google`

구글이 검색에서 가지고 있던 노하우를 LLM 에 잘 녹여냈다고 생각이 되는 논문이다.

논문의 핵심은 문서 검색을 단순 인덱스 방식이 아니라 hierachical 방식으로 접근했다는 점. 이로 인해서 로그 시간 효율성을 달성했고, 초기 검색 성능을 보장하고 LLM 노이즈에 더욱 강건해짐.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251018_img0} style={{width: 500}} />
</div>

언제나 데이터 구축 방식은 중요하다. 구글은 트리를 어떻게 구축했을까?

1. bottom-up
  - 기존 트리 구조가 없는 단순 문서 집합에서 사용.
  - 문서 임베딩이 비슷한 것들끼리 모으고, 문서 집합의 요약을 생성하고 요약이 비슷한것끼리 묶는 방식.
  - 최상위 문서 집합 개수가 M개 미만이 될떄까지 반복한다.
2. top-down
  - 기존 트리구조가 있는 경우에 사용.
  - 문서 집합을 주고, 문서 집합을 K개의 새로운 문서 집합으로 나누어달라고 요구.
  - 여전히 크기가 큰 문서집합에 대해서는 이 과정을 반복.
  - 근데 이거 해보니까 잘 안되던데 테크닉이 엄청 들어갔을 것 같다.

이렇게 구축한 검색 트리를 탐색해서 문서를 검색함. beam search 가 도입되는데 이 과정에서 beam 과 beam 을 LLM 이 비교하는게 매우 중요하다고 함.

검색 성능은 zero-shot 으로 BM25와 같은 zero-shot 모델은 능가하고, 가끔 튜닝된 SOTA 모델 성능도 이긴다고 나옴.

* 검색 효율성 외 트리의 장점 : 단순 키워드나 semantic similarity (문맥 유사도) 로는 찾을 수 없는 문서가 많다. 예를 등러 특정 정리를 이용해야 풀 수 있는 수학 문제의 경우, 단순 문서 검색으로는 해당 정리를 찾기 매우 어려움. 그런데 충분한 관련 문서를 모은 뒤 요약한다면 탐색의 단초를 잡는데 도움이 된다.

* 논